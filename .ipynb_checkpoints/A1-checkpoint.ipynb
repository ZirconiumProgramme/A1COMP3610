{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99423923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polars in /opt/homebrew/Cellar/jupyterlab/4.5.4/libexec/lib/python3.14/site-packages (1.38.1)\n",
      "Requirement already satisfied: polars-runtime-32==1.38.1 in /opt/homebrew/Cellar/jupyterlab/4.5.4/libexec/lib/python3.14/site-packages (from polars) (1.38.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: duckdb in /opt/homebrew/Cellar/jupyterlab/4.5.4/libexec/lib/python3.14/site-packages (1.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyarrow in /opt/homebrew/Cellar/jupyterlab/4.5.4/libexec/lib/python3.14/site-packages (23.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install polars\n",
    "%pip install duckdb\n",
    "%pip install pyarrow\n",
    "\n",
    "import os\n",
    "import httpx \n",
    "import polars as pl\n",
    "import duckdb\n",
    "import time\n",
    "import shutil\n",
    "import pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2ff4113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using httpx: streams in files chunk by chunk with some error checking\n",
    "def download_file(url, filename):\n",
    "    print(f\"\\nAttempting to download {filename}.......\\n\")\n",
    "    timeout = httpx.Timeout(10.0)\n",
    "\n",
    "    with httpx.Client(timeout = timeout) as client:\n",
    "        with client.stream(\"GET\", url) as response:\n",
    "            response.raise_for_status()\n",
    "            with open(filename, \"wb\") as file:\n",
    "                for chunk in response.iter_bytes():\n",
    "                    file.write(chunk)\n",
    "    print(\"\\n[Download Successful!....]\\n\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c692e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to download yellow_tripdata_2024-01.parquet.......\n",
      "\n",
      "\n",
      "[Download Successful!....]\n",
      "\n",
      "\n",
      "Attempting to download taxi_zone_lookup.csv.......\n",
      "\n",
      "\n",
      "[Download Successful!....]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Downloads the necessary files\n",
    "download_file(\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet\", \"yellow_tripdata_2024-01.parquet\")\n",
    "\n",
    "download_file(\"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\", \"taxi_zone_lookup.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3475aea4-faaa-4865-8f2f-9a8564f685df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[...All Columns Present]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Verifies that all columns exist in the DataFrame\n",
    "df_parquet = pl.read_parquet(\"yellow_tripdata_2024-01.parquet\")\n",
    "\n",
    "column_names = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'PULocationID', \n",
    "                'DOLocationID', 'passenger_count', 'trip_distance', 'fare_amount', 'tip_amount', 'total_amount', 'payment_type']\n",
    "\n",
    "missing_columns = [col for col in column_names if col not in df_parquet.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"\\nColumns{missing_columns} do not exist in the DataFrame.\\n\")\n",
    "\n",
    "print(\"\\n[...All Columns Present]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53304036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Date Columns were successfully varified]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ensures the Date columns are valid datetypes\n",
    "for col in column_names:\n",
    "    if col.endswith('_datetime'):\n",
    "        if df_parquet[col].dtype != pl.Datetime:\n",
    "            raise ValueError(f\"Column {col} is not a valid datetime type\")\n",
    "print(\"\\n[Date Columns were successfully varified]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2050fec5-0bea-4324-914b-f4790cb27d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The DataFrame contains: 2964624 rows\n",
      "\n",
      "\n",
      " [Data Validation was a success......]\n"
     ]
    }
   ],
   "source": [
    "#Report total row count\n",
    "print(f\"\\nThe DataFrame contains: {len(df_parquet)} rows\\n\")\n",
    "print(\"\\n [Data Validation was a success......]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4053defe-575a-4658-b0cf-8d389cc1c8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 0 rows removed because of the NULL values in critical columns\n",
      "\n",
      "The following rows were deleted because trip distance was 0: 60371 rows\n",
      "\n",
      "\n",
      "The following rows were deleted because of an invalid fare: 60371 rows\n",
      "\n",
      "\n",
      "The following rows were deleted because drop off time was greater than pick up time: 870 rows \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Removing nulls and filtering off data according to specifications\n",
    "filterd_df = df_parquet.drop_nulls(subset = ['tpep_pickup_datetime', 'tpep_dropoff_datetime','PULocationID', \n",
    "                'DOLocationID','fare_amount'])\n",
    "print(f\"There were {(len(df_parquet)-len(filterd_df))} rows removed because of the NULL values in critical columns\")\n",
    "\n",
    "\n",
    "\n",
    "filterd_df = filterd_df.filter((pl.col('trip_distance') > 0) & (pl.col('fare_amount') >= 0) & (pl.col('fare_amount') <= 500) &\n",
    "                               ((pl.col('tpep_pickup_datetime') < pl.col('tpep_dropoff_datetime'))))\n",
    "\n",
    "#Displaying how many rows were removed\n",
    "deleted_rows_tripdistance = df_parquet.filter(\n",
    "    (pl.col('trip_distance') <= 0)\n",
    ")\n",
    "print(f\"\\nThe following rows were deleted because trip distance was 0: {len(deleted_rows_tripdistance)} rows\\n\")\n",
    "\n",
    "deleted_rows_fare = df_parquet.filter((pl.col('fare_amount') < 0) | (pl.col('fare_amount') > 500))\n",
    "print(f\"\\nThe following rows were deleted because of an invalid fare: {len(deleted_rows_tripdistance)} rows\\n\")\n",
    "\n",
    "deleted_rows_dropoff = df_parquet.filter(((pl.col('tpep_pickup_datetime') >= pl.col('tpep_dropoff_datetime'))))\n",
    "print(f\"\\nThe following rows were deleted because drop off time was greater than pick up time: {len(deleted_rows_dropoff)} rows \\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3bfb183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the 4 derived columns \n",
    "filterd_df = filterd_df.with_columns((pl.col('tpep_dropoff_datetime') - pl.col('tpep_pickup_datetime')).alias('trip_duration_minutes'))\n",
    "\n",
    "# Calculate trip duration in minutes and add it as a new column\n",
    "filterd_df = filterd_df.with_columns(\n",
    "    (pl.col('tpep_dropoff_datetime') - pl.col('tpep_pickup_datetime')).alias('trip_duration')\n",
    ")\n",
    "\n",
    "# Convert the Duration to seconds for easier division\n",
    "filterd_df = filterd_df.with_columns(\n",
    "    (pl.col(\"trip_duration\").dt.total_seconds() / 60.0).alias(\"trip_duration_minutes\")\n",
    ")\n",
    "\n",
    "# Calculate trip speed in miles per hour and add it as a new column and handling division by zero\n",
    "\n",
    "filterd_df = filterd_df.with_columns(\n",
    "    (pl.col('trip_distance') / pl.when(pl.col('trip_duration_minutes') > 0).then(pl.col('trip_duration_minutes')).otherwise(1)).alias('trip_speed_mph')\n",
    ")\n",
    "\n",
    "#Extract the hour from the pickup time stamp\n",
    "filterd_df = filterd_df.with_columns(pl.col(\"tpep_pickup_datetime\").dt.hour().alias(\"pickup_hour\"))\n",
    "\n",
    "#Extract the day from the pickup time stamp\n",
    "filterd_df = filterd_df.with_columns(pl.col(\"tpep_pickup_datetime\").dt.day().alias(\"pickup_day_of_week\"))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d31f9fac-8a55-4fb3-80b5-f1e8f7e4c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining to taxi zones to the cleaned DataFrame\n",
    "df_taxi_zones = pl.read_csv(\"taxi_zone_lookup.csv\")\n",
    "filterd_df = (\n",
    "    filterd_df.join(\n",
    "        df_taxi_zones.rename({\n",
    "            \"LocationID\": \"PULocationID\",\n",
    "            \"Borough\": \"PU_Borough\",\n",
    "            \"Zone\": \"PU_Zone\",\n",
    "            \"service_zone\": \"PU_service_zone\"\n",
    "        }),\n",
    "        on=\"PULocationID\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        df_taxi_zones.rename({\n",
    "            \"LocationID\": \"DOLocationID\",\n",
    "            \"Borough\": \"DO_Borough\",\n",
    "            \"Zone\": \"DO_Zone\",\n",
    "            \"service_zone\": \"DO_service_zone\"\n",
    "        }),\n",
    "        on=\"DOLocationID\",\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67c30a3b-8ab5-4c1e-ad5e-c98c5d6798cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin Sql Queries\n",
    "con = duckdb.connect(':memory:')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4d7ed52-e289-4ba3-9f61-d85fde659257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Rossville/Woodrow',)\n",
      "('Rikers Island',)\n",
      "('Charleston/Tottenville',)\n",
      "('West Brighton',)\n",
      "('Stapleton',)\n",
      "(\"Governor's Island/Ellis Island/Liberty Island\",)\n",
      "('Green-Wood Cemetery',)\n",
      "('Mariners Harbor',)\n",
      "('Great Kills',)\n",
      "('Pelham Bay Park',)\n"
     ]
    }
   ],
   "source": [
    "#Answers m\n",
    "result = con.execute('''\n",
    "        SELECT \n",
    "            PU_Zone,\n",
    "        FROM\n",
    "            filterd_df\n",
    "        GROUP BY\n",
    "            PU_Zone\n",
    "        ORDER BY\n",
    "            COUNT(*)\n",
    "        Limit 10\n",
    "        ''')\n",
    "rows = result.fetchall()\n",
    "\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a4ea1-8e43-4927-8f09-fd8f50aaec46",
   "metadata": {},
   "source": [
    "Answers: m) What are the top 10 busiest pickup zones by total number of trips? (Include zone\n",
    "names from lookup table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffe71c8b-b664-45e9-a92f-21b8d696b3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 21.14253809385157)\n",
      "(1, 19.829627930228018)\n",
      "(2, 17.630085287846512)\n",
      "(3, 18.05261640070561)\n",
      "(4, 22.054804801236003)\n",
      "(5, 24.851006606279373)\n",
      "(6, 20.48472807044274)\n",
      "(7, 17.65175854679346)\n",
      "(8, 17.422563479276768)\n",
      "(9, 17.950202926403822)\n",
      "(10, 17.94626321026365)\n",
      "(11, 17.670982940755096)\n",
      "(12, 17.428575441132615)\n",
      "(13, 17.75957885597106)\n",
      "(14, 18.421483508158467)\n",
      "(15, 18.79865068122271)\n",
      "(16, 19.057906067175747)\n",
      "(17, 18.887278828368984)\n",
      "(18, 18.010771989031817)\n",
      "(19, 17.815399745889263)\n",
      "(20, 18.504986171820615)\n",
      "(21, 18.293998758270085)\n",
      "(22, 18.950691509557608)\n",
      "(23, 20.303345644649)\n"
     ]
    }
   ],
   "source": [
    "#Answers n\n",
    "result = con.execute(''' \n",
    "    SELECT\n",
    "        HOUR(tpep_dropoff_datetime) as hour, \n",
    "        AVG(fare_amount) as avg_fare\n",
    "    FROM filterd_df\n",
    "    GROUP BY hour\n",
    "''')\n",
    "rows = result.fetchall()\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30a659-bf28-42de-a578-bfb3d9dfa868",
   "metadata": {},
   "source": [
    "n) What is the average fare amount for each hour of the day? (Order by hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "099cb0c1-2cd2-47d5-a63b-684311bbf522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 4.015231811615563)\n",
      "(2, 14.73512968084832)\n",
      "(1, 80.0816084480876)\n",
      "(4, 0.7970603955476672)\n",
      "(3, 0.37096966390085734)\n"
     ]
    }
   ],
   "source": [
    "#Answer o \n",
    "result = con.execute('''\n",
    "    SELECT\n",
    "        payment_type, COUNT(*) * 100 / SUM(COUNT(*)) OVER()\n",
    "    FROM filterd_df\n",
    "    GROUP BY payment_type\n",
    "''')\n",
    "rows = result.fetchall()\n",
    "\n",
    "for row in rows:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114eb627-3be2-4dbb-a6a9-38eb5899259c",
   "metadata": {},
   "source": [
    "o) What percentage of tips use each payment type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b0321b3-a0e5-4377-8ac6-1a28727ab438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Monday', 20.45524521482601)\n",
      "('Tuesday', 20.96879815940085)\n",
      "('Thursday', 24.445185119500263)\n",
      "('Wednesday', 21.196450176726984)\n",
      "('Sunday', 20.272882016296055)\n",
      "('Saturday', 21.336866450012728)\n",
      "('Friday', 20.963300883328273)\n"
     ]
    }
   ],
   "source": [
    "result = con.execute('''\n",
    "    SELECT \n",
    "        DAYNAME(tpep_dropoff_datetime) as day,\n",
    "        AVG(tip_amount / fare_amount) * 100 as average_tip_amount\n",
    "    FROM \n",
    "        filterd_df\n",
    "    WHERE \n",
    "        fare_amount > 0 AND\n",
    "        tip_amount IS NOT NULL AND\n",
    "        fare_amount IS NOT NULL\n",
    "    GROUP BY \n",
    "        day\n",
    "''')\n",
    "\n",
    "rows = result.fetchall()\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663b3f6a-1d84-4cae-b61c-11bc8db62a03",
   "metadata": {},
   "source": [
    "p) What is the average tip percentage (tip_amount/fare_amount) by day of week, for\n",
    "credit card payments only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9cb9809-91ba-4610-947d-ff12d0694a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Upper East Side South', 'Upper East Side North', 21642)\n",
      "('Upper East Side North', 'Upper East Side South', 19199)\n",
      "('Upper East Side North', 'Upper East Side North', 15200)\n",
      "('Upper East Side South', 'Upper East Side South', 14116)\n",
      "('Midtown Center', 'Upper East Side South', 10139)\n"
     ]
    }
   ],
   "source": [
    "results = con.execute(''' \n",
    "    SELECT\n",
    "        PU_Zone,\n",
    "        DO_Zone,\n",
    "        COUNT(*) as Dropoff_Pickup_Combination_Count\n",
    "    FROM \n",
    "        filterd_df\n",
    "    GROUP BY\n",
    "        PU_Zone, DO_Zone \n",
    "    ORDER BY\n",
    "        Dropoff_Pickup_Combination_Count DESC\n",
    "    LIMIT 5;\n",
    "''')\n",
    "rows = result.fetchall()\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb77b595-04c4-40b7-8ea8-e650028b0183",
   "metadata": {},
   "source": [
    "q) What are the top 5 most common pickup-dropoff zone pairs? (Include zone names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b07a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterd_df.write_parquet('Transformed_TripData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2e31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving files to be ignored \n",
    "source_file = 'yellow_tripdata_2024-01.parquet'\n",
    "destination_folder = 'data/raw/'\n",
    "\n",
    "os.makdirs(destination_folder, exist_ok = True)\n",
    "shutil.move(source_file, os.path.join(destination_folder, os.path.basename(source_file)))\n",
    "\n",
    "source_file = 'taxi_zone_lookup.csv'\n",
    "shutil.move(source_file, os.path.join(destination_folder, os.path.basename(source_file)))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
