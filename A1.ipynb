{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99423923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polars in /opt/homebrew/Cellar/jupyterlab/4.5.4/libexec/lib/python3.14/site-packages (1.38.1)\n",
      "Requirement already satisfied: polars-runtime-32==1.38.1 in /opt/homebrew/Cellar/jupyterlab/4.5.4/libexec/lib/python3.14/site-packages (from polars) (1.38.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: duckdb in /opt/homebrew/Cellar/jupyterlab/4.5.4/libexec/lib/python3.14/site-packages (1.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyarrow in /opt/homebrew/Cellar/jupyterlab/4.5.4/libexec/lib/python3.14/site-packages (23.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Cellar/jupyterlab/4.5.4/libexec/lib/python3.14/site-packages (2.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Cellar/jupyterlab/4.5.4/libexec/lib/python3.14/site-packages (3.0.1)\n",
      "Requirement already satisfied: numpy>=2.3.3 in /opt/homebrew/Cellar/jupyterlab/4.5.4/libexec/lib/python3.14/site-packages (from pandas) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Cellar/jupyterlab/4.5.4/libexec/lib/python3.14/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Cellar/jupyterlab/4.5.4/libexec/lib/python3.14/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install polars\n",
    "%pip install duckdb\n",
    "%pip install pyarrow\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "import os\n",
    "import httpx \n",
    "import polars as pl\n",
    "import duckdb\n",
    "import time\n",
    "import shutil\n",
    "import pyarrow\n",
    "import numpy\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2ff4113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using httpx: streams in files chunk by chunk with some error checking\n",
    "def download_file(url, filename):\n",
    "    print(f\"\\nAttempting to download {filename}.......\\n\")\n",
    "    timeout = httpx.Timeout(10.0)\n",
    "\n",
    "    with httpx.Client(timeout = timeout) as client:\n",
    "        with client.stream(\"GET\", url) as response:\n",
    "            response.raise_for_status()\n",
    "            with open(filename, \"wb\") as file:\n",
    "                for chunk in response.iter_bytes():\n",
    "                    file.write(chunk)\n",
    "    print(\"\\n[Download Successful!....]\\n\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c692e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to download yellow_tripdata_2024-01.parquet.......\n",
      "\n",
      "\n",
      "[Download Successful!....]\n",
      "\n",
      "\n",
      "Attempting to download taxi_zone_lookup.csv.......\n",
      "\n",
      "\n",
      "[Download Successful!....]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Downloads the necessary files\n",
    "download_file(\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet\", \"yellow_tripdata_2024-01.parquet\")\n",
    "\n",
    "download_file(\"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\", \"taxi_zone_lookup.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3475aea4-faaa-4865-8f2f-9a8564f685df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[...All Columns Present]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Verifies that all columns exist in the DataFrame\n",
    "df_parquet = pl.read_parquet(\"yellow_tripdata_2024-01.parquet\")\n",
    "\n",
    "column_names = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'PULocationID', \n",
    "                'DOLocationID', 'passenger_count', 'trip_distance', 'fare_amount', 'tip_amount', 'total_amount', 'payment_type']\n",
    "\n",
    "missing_columns = [col for col in column_names if col not in df_parquet.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"\\nColumns{missing_columns} do not exist in the DataFrame.\\n\")\n",
    "\n",
    "print(\"\\n[...All Columns Present]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53304036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Date Columns were successfully varified]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ensures the Date columns are valid datetypes\n",
    "for col in column_names:\n",
    "    if col.endswith('_datetime'):\n",
    "        if df_parquet[col].dtype != pl.Datetime:\n",
    "            raise ValueError(f\"Column {col} is not a valid datetime type\")\n",
    "print(\"\\n[Date Columns were successfully varified]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2050fec5-0bea-4324-914b-f4790cb27d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The DataFrame contains: 2964624 rows\n",
      "\n",
      "\n",
      " [Data Validation was a success......]\n"
     ]
    }
   ],
   "source": [
    "#Report total row count\n",
    "print(f\"\\nThe DataFrame contains: {len(df_parquet)} rows\\n\")\n",
    "print(\"\\n [Data Validation was a success......]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4053defe-575a-4658-b0cf-8d389cc1c8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 0 rows removed because of the NULL values in critical columns\n",
      "\n",
      "The following rows were deleted because trip distance was 0: 60371 rows\n",
      "\n",
      "\n",
      "The following rows were deleted because of an invalid fare: 60371 rows\n",
      "\n",
      "\n",
      "The following rows were deleted because drop off time was greater than pick up time: 870 rows \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Removing nulls and filtering off data according to specifications\n",
    "filterd_df = df_parquet.drop_nulls(subset = ['tpep_pickup_datetime', 'tpep_dropoff_datetime','PULocationID', \n",
    "                'DOLocationID','fare_amount'])\n",
    "print(f\"There were {(len(df_parquet)-len(filterd_df))} rows removed because of the NULL values in critical columns\")\n",
    "\n",
    "\n",
    "\n",
    "filterd_df = filterd_df.filter((pl.col('trip_distance') > 0) & (pl.col('fare_amount') >= 0) & (pl.col('fare_amount') <= 500) &\n",
    "                               ((pl.col('tpep_pickup_datetime') < pl.col('tpep_dropoff_datetime'))))\n",
    "\n",
    "#Displaying how many rows were removed\n",
    "deleted_rows_tripdistance = df_parquet.filter(\n",
    "    (pl.col('trip_distance') <= 0)\n",
    ")\n",
    "print(f\"\\nThe following rows were deleted because trip distance was 0: {len(deleted_rows_tripdistance)} rows\\n\")\n",
    "\n",
    "deleted_rows_fare = df_parquet.filter((pl.col('fare_amount') < 0) | (pl.col('fare_amount') > 500))\n",
    "print(f\"\\nThe following rows were deleted because of an invalid fare: {len(deleted_rows_tripdistance)} rows\\n\")\n",
    "\n",
    "deleted_rows_dropoff = df_parquet.filter(((pl.col('tpep_pickup_datetime') >= pl.col('tpep_dropoff_datetime'))))\n",
    "print(f\"\\nThe following rows were deleted because drop off time was greater than pick up time: {len(deleted_rows_dropoff)} rows \\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3bfb183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the 4 derived columns \n",
    "filterd_df = filterd_df.with_columns((pl.col('tpep_dropoff_datetime') - pl.col('tpep_pickup_datetime')).alias('trip_duration_minutes'))\n",
    "\n",
    "# Calculate trip duration in minutes and add it as a new column\n",
    "filterd_df = filterd_df.with_columns(\n",
    "    (pl.col('tpep_dropoff_datetime') - pl.col('tpep_pickup_datetime')).alias('trip_duration')\n",
    ")\n",
    "\n",
    "# Convert the Duration to seconds for easier division\n",
    "filterd_df = filterd_df.with_columns(\n",
    "    (pl.col(\"trip_duration\").dt.total_seconds() / 60.0).alias(\"trip_duration_minutes\")\n",
    ")\n",
    "\n",
    "# Calculate trip speed in miles per hour and add it as a new column and handling division by zero\n",
    "\n",
    "filterd_df = filterd_df.with_columns(\n",
    "    (pl.col('trip_distance') / pl.when(pl.col('trip_duration_minutes') > 0).then(pl.col('trip_duration_minutes')).otherwise(1)).alias('trip_speed_mph')\n",
    ")\n",
    "\n",
    "#Extract the hour from the pickup time stamp\n",
    "filterd_df = filterd_df.with_columns(pl.col(\"tpep_pickup_datetime\").dt.hour().alias(\"pickup_hour\"))\n",
    "\n",
    "#Extract the day from the pickup time stamp\n",
    "filterd_df = filterd_df.with_columns(pl.col(\"tpep_pickup_datetime\").dt.day().alias(\"pickup_day_of_week\"))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d31f9fac-8a55-4fb3-80b5-f1e8f7e4c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining to taxi zones to the cleaned DataFrame\n",
    "df_taxi_zones = pl.read_csv(\"taxi_zone_lookup.csv\")\n",
    "filterd_df = (\n",
    "    filterd_df.join(\n",
    "        df_taxi_zones.rename({\n",
    "            \"LocationID\": \"PULocationID\",\n",
    "            \"Borough\": \"PU_Borough\",\n",
    "            \"Zone\": \"PU_Zone\",\n",
    "            \"service_zone\": \"PU_service_zone\"\n",
    "        }),\n",
    "        on=\"PULocationID\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .join(\n",
    "        df_taxi_zones.rename({\n",
    "            \"LocationID\": \"DOLocationID\",\n",
    "            \"Borough\": \"DO_Borough\",\n",
    "            \"Zone\": \"DO_Zone\",\n",
    "            \"service_zone\": \"DO_service_zone\"\n",
    "        }),\n",
    "        on=\"DOLocationID\",\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67c30a3b-8ab5-4c1e-ad5e-c98c5d6798cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x110f030b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Begin Sql Queries\n",
    "con = duckdb.connect(':memory:')\n",
    "con.register(\"filterd_df\", filterd_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d18a28a-c8ef-4cae-917d-6201858015d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_folder = 'queries/' \n",
    "os.makedirs(destination_folder, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4d7ed52-e289-4ba3-9f61-d85fde659257",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 2)\n",
      "┌──────────────────────────────┬─────────────────┐\n",
      "│ PU_Zone                      ┆ Number_Of_Trips │\n",
      "│ ---                          ┆ ---             │\n",
      "│ str                          ┆ i64             │\n",
      "╞══════════════════════════════╪═════════════════╡\n",
      "│ Midtown Center               ┆ 140161          │\n",
      "│ Upper East Side South        ┆ 140131          │\n",
      "│ JFK Airport                  ┆ 138474          │\n",
      "│ Upper East Side North        ┆ 133975          │\n",
      "│ Midtown East                 ┆ 104353          │\n",
      "│ Times Sq/Theatre District    ┆ 102972          │\n",
      "│ Penn Station/Madison Sq West ┆ 102160          │\n",
      "│ Lincoln Square East          ┆ 101800          │\n",
      "│ LaGuardia Airport            ┆ 87714           │\n",
      "│ Upper West Side South        ┆ 86473           │\n",
      "└──────────────────────────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "#Answers m\n",
    "result = con.execute('''\n",
    "        SELECT \n",
    "            PU_Zone,\n",
    "            COUNT(*) as Number_Of_Trips\n",
    "        FROM\n",
    "            filterd_df\n",
    "        GROUP BY\n",
    "            PU_Zone\n",
    "        ORDER BY\n",
    "            COUNT(*) DESC\n",
    "        Limit 10\n",
    "        ''').pl()\n",
    "print(result)\n",
    "result.write_parquet(\"queries/ten_busiest_pickupzones.parquet\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a4ea1-8e43-4927-8f09-fd8f50aaec46",
   "metadata": {},
   "source": [
    "Answers: m) What are the top 10 busiest pickup zones by total number of trips? (Include zone\n",
    "names from lookup table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffe71c8b-b664-45e9-a92f-21b8d696b3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (24, 2)\n",
      "┌──────┬───────────┐\n",
      "│ hour ┆ avg_fare  │\n",
      "│ ---  ┆ ---       │\n",
      "│ i64  ┆ f64       │\n",
      "╞══════╪═══════════╡\n",
      "│ 0    ┆ 21.142538 │\n",
      "│ 1    ┆ 19.829628 │\n",
      "│ 2    ┆ 17.630085 │\n",
      "│ 3    ┆ 18.052616 │\n",
      "│ 4    ┆ 22.054805 │\n",
      "│ …    ┆ …         │\n",
      "│ 19   ┆ 17.8154   │\n",
      "│ 20   ┆ 18.504986 │\n",
      "│ 21   ┆ 18.293999 │\n",
      "│ 22   ┆ 18.950692 │\n",
      "│ 23   ┆ 20.303346 │\n",
      "└──────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "#Answers n\n",
    "result = con.execute(''' \n",
    "    SELECT\n",
    "        HOUR(tpep_dropoff_datetime) as hour, \n",
    "        AVG(fare_amount) as avg_fare\n",
    "    FROM filterd_df\n",
    "    GROUP BY hour \n",
    "''').pl()\n",
    "\n",
    "print(result)\n",
    "result.write_parquet(\"queries/averagefare_by_hour.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30a659-bf28-42de-a578-bfb3d9dfa868",
   "metadata": {},
   "source": [
    "n) What is the average fare amount for each hour of the day? (Order by hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "099cb0c1-2cd2-47d5-a63b-684311bbf522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌──────────────┬────────────────┐\n",
      "│ payment_type ┆ Tip_Percentage │\n",
      "│ ---          ┆ ---            │\n",
      "│ i64          ┆ f64            │\n",
      "╞══════════════╪════════════════╡\n",
      "│ 0            ┆ 4.015232       │\n",
      "│ 2            ┆ 14.73513       │\n",
      "│ 1            ┆ 80.081608      │\n",
      "│ 4            ┆ 0.79706        │\n",
      "│ 3            ┆ 0.37097        │\n",
      "└──────────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "#Answer o \n",
    "result = con.execute('''\n",
    "    SELECT\n",
    "        payment_type, COUNT(*) * 100 / SUM(COUNT(*)) OVER() as Tip_Percentage\n",
    "    FROM filterd_df\n",
    "    GROUP BY payment_type\n",
    "''').pl()\n",
    "print(result)\n",
    "result.write_parquet(\"queries/tippercent_by_paymenttype.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114eb627-3be2-4dbb-a6a9-38eb5899259c",
   "metadata": {},
   "source": [
    "o) What percentage of tips use each payment type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b0321b3-a0e5-4377-8ac6-1a28727ab438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (7, 2)\n",
      "┌───────────┬────────────────────┐\n",
      "│ day       ┆ average_tip_amount │\n",
      "│ ---       ┆ ---                │\n",
      "│ str       ┆ f64                │\n",
      "╞═══════════╪════════════════════╡\n",
      "│ Thursday  ┆ 24.445185          │\n",
      "│ Tuesday   ┆ 20.968798          │\n",
      "│ Saturday  ┆ 21.336866          │\n",
      "│ Sunday    ┆ 20.272882          │\n",
      "│ Wednesday ┆ 21.19645           │\n",
      "│ Monday    ┆ 20.455245          │\n",
      "│ Friday    ┆ 20.963301          │\n",
      "└───────────┴────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "#Answer for p\n",
    "result = con.execute('''\n",
    "    SELECT \n",
    "        DAYNAME(tpep_dropoff_datetime) as day,\n",
    "        AVG(tip_amount / fare_amount) * 100 as average_tip_amount\n",
    "    FROM \n",
    "        filterd_df\n",
    "    WHERE \n",
    "        fare_amount > 0 AND\n",
    "        tip_amount IS NOT NULL AND\n",
    "        fare_amount IS NOT NULL\n",
    "    GROUP BY \n",
    "        day\n",
    "''').pl()\n",
    "\n",
    "\n",
    "print(result)\n",
    "result.write_parquet(\"queries/averagetip_percent_by_dayoweek.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663b3f6a-1d84-4cae-b61c-11bc8db62a03",
   "metadata": {},
   "source": [
    "p) What is the average tip percentage (tip_amount/fare_amount) by day of week, for\n",
    "credit card payments only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9cb9809-91ba-4610-947d-ff12d0694a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌───────────────────────┬───────────────────────┬─────────────────────────────────┐\n",
      "│ PU_Zone               ┆ DO_Zone               ┆ Dropoff_Pickup_Combination_Cou… │\n",
      "│ ---                   ┆ ---                   ┆ ---                             │\n",
      "│ str                   ┆ str                   ┆ i64                             │\n",
      "╞═══════════════════════╪═══════════════════════╪═════════════════════════════════╡\n",
      "│ Upper East Side South ┆ Upper East Side North ┆ 21642                           │\n",
      "│ Upper East Side North ┆ Upper East Side South ┆ 19199                           │\n",
      "│ Upper East Side North ┆ Upper East Side North ┆ 15200                           │\n",
      "│ Upper East Side South ┆ Upper East Side South ┆ 14116                           │\n",
      "│ Midtown Center        ┆ Upper East Side South ┆ 10139                           │\n",
      "└───────────────────────┴───────────────────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "#Answer for q\n",
    "result = con.execute(''' \n",
    "    SELECT\n",
    "        PU_Zone,\n",
    "        DO_Zone,\n",
    "        COUNT(*) as Dropoff_Pickup_Combination_Count\n",
    "    FROM \n",
    "        filterd_df\n",
    "    GROUP BY\n",
    "        PU_Zone, DO_Zone \n",
    "    ORDER BY\n",
    "        Dropoff_Pickup_Combination_Count DESC\n",
    "    LIMIT 5;\n",
    "''').pl()\n",
    "\n",
    "\n",
    "print(result)\n",
    "result.write_parquet(\"queries/mostfrquent_pickup_dropoff_pairs.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb77b595-04c4-40b7-8ea8-e650028b0183",
   "metadata": {},
   "source": [
    "q) What are the top 5 most common pickup-dropoff zone pairs? (Include zone names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42c28d0c-b9e2-47b6-8522-ebc32830dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One extra query to make the heatmap\n",
    "result = con.execute('''\n",
    "    SELECT \n",
    "        DAYNAME(tpep_pickup_datetime) as day_of_week,\n",
    "        HOUR(tpep_pickup_datetime) as hour,\n",
    "        COUNT(*) as trip_count\n",
    "    FROM filterd_df\n",
    "    GROUP BY day_of_week, hour\n",
    "    ORDER BY hour\n",
    "''').pl()\n",
    "\n",
    "\n",
    "result_heat.write_parquet(\"queries/trips_by_day_hour.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c71b07a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a cleaned and updated Trip Data file to use in the dashboard\n",
    "filterd_df.write_parquet('Transformed_TripData.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f2e31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving files to be ignored \n",
    "source_file = 'yellow_tripdata_2024-01.parquet'\n",
    "destination_folder = 'data/raw/'\n",
    "\n",
    "os.makedirs(destination_folder, exist_ok = True)\n",
    "shutil.move(source_file, os.path.join(destination_folder, os.path.basename(source_file)))\n",
    "\n",
    "source_file = 'taxi_zone_lookup.csv'\n",
    "shutil.move(source_file, os.path.join(destination_folder, os.path.basename(source_file)))\n",
    "\n",
    "file = open(\"data/raw/.gitignore\", \"w\")\n",
    "file.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9da7fad-8535-4eee-b654-35c33a522d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the .gitignore files\n",
    "file = open(\"data/.gitignore\", \"w\")\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
